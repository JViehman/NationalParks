install.packages("shiny")
shiny::runApp()
options(repos = c(CRAN = "http://cran.rstudio.com"))
install.packages("randomForest")
install.packages("gbm")
misClass =function(predClass,trueClass,produceOutput=FALSE){
confusionMat = table(predClass,trueClass)
if(produceOutput){
return(1-sum(diag(confusionMat))/sum(confusionMat))
}
else{
print('misclass')
print(1-sum(diag(confusionMat))/sum(confusionMat))
print('confusion mat')
print(confusionMat)
}
}
# this can be called using:
#     (assuming you make the appropriately named test predictions)
# misClass(Yhat,Y_0)
require(randomForest)
require(gbm)
require(caret)
load("spam.Rdata")
train = spam$train
test  = !train
X     = spam$XdataF[train,]
X_0   = spam$XdataF[test,]
Y     = factor(spam$Y[train])
Y_0   = factor(spam$Y[test])
checkNumberItersF = function(ntrees = 5, tolParm = 1, maxIter = 10, verbose = 0){
###
# tolParm: iterations will continue until the percent decrease
#          is less than tolParm
###
misClassOut   = list()
totalTreesOut = list()
n              = nrow(X)
votes          = matrix(0,nrow=n,ncol=2)
totalTrees     = 0
iterations     = 0
misClassOld   = 1
while(iterations < maxIter){
votes[is.nan(votes)] = 0
iterations    = iterations + 1
totalTrees    = totalTrees + ntrees
if(verbose >= 2){cat('Total trees: ',totalTrees,'\n')}
outRf        = randomForest(X, Y,ntree = ntrees)
oob.times        = outRf$oob.times
votes_iterations = outRf$votes*oob.times
votes[oob.times>0,] = matrix(votes + votes_iterations,nrow=n)[oob.times>0,]
if(min(apply(votes,1,sum)) == 0){next}
Yhat          = apply(votes,1,which.max) - 1
misClassNew  = misClass(Yhat,Y,produceOutput = TRUE)
misClassOut[[iterations]]   = misClassNew
totalTreesOut[[iterations]] = totalTrees
percentChange = 100*(misClassNew - misClassOld)/misClassOld
if(verbose >= 1){cat('% change: ',percentChange,'\n')}
if(percentChange > -tolParm){break}
misClassOld = misClassNew
}
if(iterations == maxIter){
stop("too many iterations, try a larger ntrees or maxIter value")
}
return(list('misClass' = unlist(misClassOut),
'totalTree' = unlist(totalTreesOut)))
}
set.seed(1)
checkNumberIters = checkNumberItersF(ntrees = 5, tolParm = 1, maxIter = 15, verbose = 2)
iterations = length(checkNumberIters$totalTree)
ntrees = max(checkNumberIters$totalTree)
outRf  = randomForest(X, Y, ntree = ntrees, importance = T, proximity = T)
preds = predict(outRf, X_0)
confmat = confusionMatrix(preds, Y_0)
#### Answer 1.2.1 Fill in the appropriate code here to define the objects.
####              Answer the questions by using the `r objectName` syntax.
####              I'll just write the first example involving test misclassification rate
testError = 1-confmat$overall['Accuracy']
oobMisclass = misClass(preds, Y_0)
sens = confmat$byClass['Sensitivity']
spec = confmat$byClass['Specificity']
precision = precision(preds, Y_0)
recall = recall(preds, Y_0)#### replace with correct answer
varImpPlot(outRf, type = 1)#### Answer 1.3.1
lambdaGrid            = c(.0001,.1,1,10)
interaction.depthGrid = c(4,5,6)
n.treesGrid           = c(500,1000)
resultsGrid           = array(0,dim=c(length(lambdaGrid),
length(interaction.depthGrid),
length(n.treesGrid)),
dimnames = list('lambda'=as.character(lambdaGrid),
'interaction'=as.character(interaction.depthGrid),
'n.trees'=as.character(n.treesGrid)))
resultsBoost          = list('bernoulli' = resultsGrid,
'adaboost'  = resultsGrid)
set.seed(1)
verbose = 0
Ychar   = as.character(Y) # gbm doesn't accept factor Y
Ychar_0 = as.character(Y_0)
for(distribution in c('bernoulli','adaboost')){
lamIter = 0
for(lambda in lambdaGrid){
lamIter = lamIter + 1
intIter = 0
for(interaction.depth in interaction.depthGrid){
intIter  = intIter + 1
treeIter = 0
for(n.trees in n.treesGrid){
treeIter = treeIter + 1
boostOut = gbm(Ychar~.,data=X,
n.trees=n.trees, interaction.depth=interaction.depth,
shrinkage=lambda, distribution = distribution)
fHat  = predict(boostOut,X_0,n.trees=n.trees)
Yhat = rep(0,nrow(X_0))
Yhat[fHat > 0] = 1
Yhat = as.factor(Yhat)
if(verbose > 0){
cat('lambda = ',lambda,' interaction.depth = ',interaction.depth, ' lambda = ',lambda,' n.trees = ',n.trees,'\n')
}
if(verbose > 1){
misClass(Yhat,Ychar_0)
}
resultsBoost[[distribution]][lamIter,intIter,treeIter] = misClass(Yhat,Ychar_0, produceOutput = TRUE)
}
}
}
}
resultsBoost
shiny::runApp()
